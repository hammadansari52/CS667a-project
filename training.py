# -*- coding: utf-8 -*-
"""Copy of Untitled (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qtCs6PJ-hB1K-hqDvyCUgkbcnkH_MJMU
"""

import numpy as np
import os
import PIL
import PIL.Image
import tensorflow as tf
import matplotlib.pyplot as plt
from progressbar import ProgressBar
from time import perf_counter
import cv2 as cv
import pandas as pd
import pathlib
import psutil
from tensorflow.keras.preprocessing import image

tf.__version__

classes = ['0_Healthy', '1_Unhealthy']

from google.colab import drive

drive.mount('/content/gdrive/', force_remount=True)

IMG_SHAPE = 224
BATCH_SIZE = 32

dataset_dir = "/content/gdrive/MyDrive/iot/data"
train_dir = os.path.join(dataset_dir, 'train')
val_dir = os.path.join(dataset_dir, 'validation')
train_data = tf.keras.utils.image_dataset_from_directory(train_dir, 
                                                         labels = "inferred", 
                                                         color_mode='rgb', 
                                                         batch_size=BATCH_SIZE, 
                                                         image_size=(IMG_SHAPE, IMG_SHAPE))

val_data = tf.keras.utils.image_dataset_from_directory(val_dir, 
                                                       labels = "inferred", 
                                                       color_mode='rgb', 
                                                       batch_size=BATCH_SIZE,
                                                       image_size=(IMG_SHAPE, IMG_SHAPE))

num_classes = len(train_data.class_names)

resize_and_rescale = tf.keras.Sequential([
  tf.keras.layers.Resizing(IMG_SHAPE, IMG_SHAPE),
  tf.keras.layers.Rescaling(1./255)
])

# data_augmentation = tf.keras.Sequential([
#   tf.keras.layers.RandomFlip("horizontal_and_vertical"),
#   tf.keras.layers.RandomRotation(0.2),
# ])

import tensorflow_hub as hub
inception_v3 = "https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4"

feature_extractor_model = inception_v3

feature_extractor_layer = hub.KerasLayer(
    feature_extractor_model,
    input_shape=(IMG_SHAPE, IMG_SHAPE, 3),
    trainable=False)

# for image_batch, labels_batch in train_data:
#   feature_batch = feature_extractor_layer(image_batch)
#   print(feature_batch.shape)
#   break

model = tf.keras.Sequential([
    resize_and_rescale,
  feature_extractor_layer,
  tf.keras.layers.Dense(num_classes, activation = 'softmax')
]) 

model.build(input_shape=(None, IMG_SHAPE, IMG_SHAPE, 3))
model.summary()

# for image_batch, labels_batch in train_data:
#   predictions = model(image_batch)
#   break

# predicted_labels = np.argmax(np.array(predictions), axis = 1)
# orig_labels = np.array(labels_batch)
# accuracy = np.average(predicted_labels == orig_labels)
# print(accuracy)

model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss="sparse_categorical_crossentropy",
    metrics=['acc'])

NUM_EPOCHS = 20

history = model.fit(train_data,
                    validation_data=val_data,
                    epochs=NUM_EPOCHS)

def plot_history(hist,Text):
  history=hist
  acc = history.history["acc"]
  val_acc = history.history["val_acc"]

  loss = history.history["loss"]
  val_loss = history.history["val_loss"]

  epochs_range = range(len(history.epoch))

  plt.figure(figsize=(10,10))
  plt.subplot(1,2,1)
  plt.plot(epochs_range,acc,label="Train Accuracy")
  plt.plot(epochs_range,val_acc,label="Validation Accuracy")
  plt.legend(loc = 'lower right')
  plt.title("Accuracy")
  plt.subplot(1,2,2)
  plt.plot(epochs_range,loss,label="Train Loss")
  plt.plot(epochs_range,val_loss,label="Validation Loss")
  plt.legend(loc = 'upper right')
  plt.title("Loss")
  plt.suptitle(Text)

plot_history(history,"InceptionV3")

model.save('/content/gdrive/MyDrive/iot_second/coffee1')

loaded_model = tf.keras.models.load_model('/content/gdrive/MyDrive/iot_second/coffee1')
loaded_model.summary()

converter = tf.lite.TFLiteConverter.from_saved_model('/content/gdrive/MyDrive/iot_second/coffee1')
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
tflite_model_file = pathlib.Path('/content/gdrive/MyDrive/iot_second/coffee1_noquant.tflite')
tflite_model_file.write_bytes(tflite_model)

converter = tf.lite.TFLiteConverter.from_saved_model('/content/gdrive/MyDrive/iot_second/coffee1')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
tflite_model_file = pathlib.Path('/content/gdrive/MyDrive/iot_second/coffee1_dyn_quant.tflite')
tflite_model_file.write_bytes(tflite_model)

converter = tf.lite.TFLiteConverter.from_saved_model('/content/gdrive/MyDrive/iot_second/coffee1')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
tflite_model_file = pathlib.Path('/content/gdrive/MyDrive/iot_second/coffee1_f16_quant.tflite')
tflite_model_file.write_bytes(tflite_model)